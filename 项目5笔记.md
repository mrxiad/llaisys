# LLAISYS 项目5笔记（分布式推理 / MPI Tensor Parallel）

完成时间：2026-02-19

## 1. 目标

按 `Project #5` 要求，在 CPU 路径上使用 MPI 实现分布式推理，完成张量并行相关流程：

- 多进程协同推理（`mpirun -np N`）
- 按词表分片做局部 argmax
- 通过 MPI 聚合局部结果得到全局 next token

## 2. 主要改动

### 2.1 Qwen2 后端新增分片 argmax C API

修改文件：

- `include/llaisys/models/qwen2.h`
- `src/llaisys/qwen2.cc`

新增接口：

- `llaisysQwen2ModelInferShardArgmax(model, token_ids, ntoken, vocab_start, vocab_end, max_idx, max_val)`

实现说明：

- 在单步前向中保留原有解码路径，同时支持对 `logits[vocab_start:vocab_end)` 做局部 argmax。
- 返回的是全局词表索引（已加 shard 偏移）和对应 logit 值。
- 继续复用现有 KV-cache/prefix 逻辑，保证增量推理行为一致。

### 2.2 Python ctypes 与模型封装扩展

修改文件：

- `python/llaisys/libllaisys/models_qwen2.py`
- `python/llaisys/models/qwen2.py`

新增能力：

- 绑定 `llaisysQwen2ModelInferShardArgmax` ctypes 签名
- `Qwen2.infer_shard_argmax(inputs, vocab_start, vocab_end) -> (idx, val)`

### 2.3 新增 MPI 分布式推理模块

新增文件：

- `python/llaisys/distributed/__init__.py`
- `python/llaisys/distributed/mpi_tp_qwen2.py`

实现流程：

- `rank` 根据 `world_size` 切分词表区间
- 每个 `rank` 对本地词表分片调用 `infer_shard_argmax`
- `rank0` gather 所有 `(logit, token_idx)` 后选全局最大
- 广播 next token 给所有进程，进入下一轮生成

## 3. 运行方式

### 3.1 构建与安装

```bash
xmake -j 8
xmake install -o .
./.venv310/bin/pip install -e ./python
```

### 3.2 MPI 运行（CPU）

```bash
export HWLOC_COMPONENTS=-gl
mpirun --oversubscribe -np 2 \
  ./.venv310/bin/python -m llaisys.distributed.mpi_tp_qwen2 \
  --model /path/to/model \
  --prompt "Hi" \
  --max-new-tokens 1
```

说明：

- 当前环境（WSL）下，OpenMPI 的 hwloc 图形探测路径会导致 `mpirun` 卡住；设置 `HWLOC_COMPONENTS=-gl` 可正常运行。

## 4. 验证结果

使用模型：

- `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`（本地缓存快照）

### 4.1 回归测试（单机）

执行：

```bash
./.venv310/bin/python test/test_infer.py \
  --model /home/mrxiad/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 \
  --test --max_steps 1 --prompt "Hi"
```

结果：

- `Test passed!`
- 生成 token 与 PyTorch 一致：`71486`（解码文本：`Alright`）

### 4.2 MPI 分布式实测（2 进程）

执行（两次）：

```bash
HWLOC_COMPONENTS=-gl mpirun --oversubscribe -np 2 \
  ./.venv310/bin/python -m llaisys.distributed.mpi_tp_qwen2 \
  --model /home/mrxiad/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 \
  --prompt "Hi" --max-new-tokens 1
```

结果：

- `world_size=2`
- `generated_tokens=1`
- 输出文本：`Alright`
- 两次运行均一致

## 5. 完成状态

- [x] CPU MPI 分布式推理流程（rank 间协同）
- [x] 词表分片局部 argmax + 全局归约
- [x] Python 分布式入口脚本
- [x] 回归与分布式实测
